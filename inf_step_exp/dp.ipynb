{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Function Training Algorithm for AMM\n",
    "\n",
    "## Model Architecture\n",
    "- Neural network with 3 input nodes (p, x, y)\n",
    "- 3 hidden layers with 64 nodes each and ReLU activation\n",
    "- 1 output node (value)\n",
    "- Uses both main network and target network for stable training\n",
    "\n",
    "## Parameters\n",
    "- L: Constant product parameter (L² = x*y)\n",
    "- γ: Fee rate (0.003)\n",
    "- σ: Price volatility (0.5)\n",
    "- δt: Time step (1)\n",
    "- μ: Price drift (0.0)\n",
    "- Fee model: 'distribute'\n",
    "- Fee source: 'incoming' or 'outgoing'\n",
    "\n",
    "## Training Process\n",
    "\n",
    "### For each epoch:\n",
    "1. Generate training data:\n",
    "   - Sample x values uniformly from [50, 150]\n",
    "   - Calculate y = L²/x\n",
    "   - Calculate price bounds: p_min = (y/x)(1-γ), p_max = (y/x)/(1-γ)\n",
    "   - Sample p values uniformly between bounds\n",
    "\n",
    "2. For each batch:\n",
    "\n",
    "   a. Calculate target values:\n",
    "      - Use Gauss-Legendre quadrature (50 points) for numerical integration\n",
    "      - For each state (p,x,y):\n",
    "        * Generate future price points using log-normal distribution\n",
    "        * Calculate new (x,y) positions based on AMM mechanics\n",
    "        * Compute future values using target network\n",
    "        * Calculate expected value through numerical integration\n",
    "         $$\n",
    "         E[V(p')] = \\sum_{i}^{50} w_i \\cdot V(p'_i) \\cdot f(p'_i \\mid p)\n",
    "         $$\n",
    "\n",
    "         where:\n",
    "         - $w_i$ are the Gauss-Legendre weights\n",
    "         - $V(p'_i)$ is the value function at future price $p'_i$\n",
    "         - $f(p'_i \\mid p)$ is the log-normal PDF:\n",
    "\n",
    "   b. Update main network:\n",
    "      - Forward pass to get predicted values\n",
    "      - Calculate MSE loss\n",
    "      - Backpropagate and update weights\n",
    "      - Clip gradients at norm 1.0\n",
    "\n",
    "   c. Update target network:\n",
    "      - Soft update with τ = 0.0005\n",
    "      - θ_target = τ*θ_current + (1-τ)*θ_target\n",
    "\n",
    "3. Adjust learning rate:\n",
    "   - Decay by factor 0.95 every 10 epochs\n",
    "\n",
    "### Training Configuration\n",
    "- Number of epochs: 200\n",
    "- Batch size: 64\n",
    "- Initial learning rate: 0.0001\n",
    "- Samples per epoch: 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp import main\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ValueFunctionNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, normalize=True):\n",
    "        super(ValueFunctionNN, self).__init__()\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        # Statistics for normalization\n",
    "        self.register_buffer('L', torch.tensor(1.0))\n",
    "        \n",
    "        # Neural network layers\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def normalize_input(self, state):\n",
    "        if not self.normalize:\n",
    "            return state\n",
    "            \n",
    "        normalized = torch.zeros_like(state)\n",
    "        normalized[:, 1] = state[:, 1] / self.L\n",
    "        normalized[:, 2] = state[:, 2] / self.L\n",
    "        return normalized\n",
    "    \n",
    "    def forward(self, state):\n",
    "        # Normalize the input state\n",
    "        normalized_state = self.normalize_input(state)\n",
    "        # Process through the network\n",
    "        return self.network(normalized_state)\n",
    "\n",
    "def load_model(model_path):\n",
    "    try:\n",
    "        # Create model instance\n",
    "        model = ValueFunctionNN()\n",
    "        \n",
    "        # Load state dict\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "        # Handle different state dict formats\n",
    "        if isinstance(state_dict, dict):\n",
    "            if 'state_dict' in state_dict:\n",
    "                state_dict = state_dict['state_dict']\n",
    "            elif 'model_state_dict' in state_dict:\n",
    "                state_dict = state_dict['model_state_dict']\n",
    "        \n",
    "        # Load the state dict\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        \n",
    "        logger.info(f\"Successfully loaded model from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model {model_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Rest of your code remains the same, starting from:\n",
    "# Load both models\n",
    "incoming_model_path = '/home/shiftpub/Dynamic_AMM/inf_step_exp/mc_value_network_distribute_incoming.pth'\n",
    "outgoing_model_path = '/home/shiftpub/Dynamic_AMM/inf_step_exp/mc_value_network_distribute_outgoing.pth'\n",
    "\n",
    "try:\n",
    "    incoming_model = load_model(incoming_model_path)\n",
    "    print(\"Incoming fee model loaded successfully\") \n",
    "except Exception as e:\n",
    "    print(f\"Error loading incoming model: {e}\")\n",
    "    incoming_model = None\n",
    "\n",
    "try:\n",
    "    outgoing_model = load_model(outgoing_model_path)\n",
    "    print(\"Outgoing fee model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading outgoing model: {e}\")\n",
    "    outgoing_model = None\n",
    "\n",
    "# Function to calculate immediate reward\n",
    "def immediate_reward(state):\n",
    "    p, x, y = state\n",
    "    return p * x + y\n",
    "\n",
    "# Function to generate test states across the entire valid state space\n",
    "def generate_test_states(L=100, gamma=0.003, num_x=1000, num_p_per_x=10):\n",
    "    test_states = []\n",
    "    \n",
    "    # Generate x values in range [50, 150]\n",
    "    x_values = np.linspace(L*0.95, L*1.05, num_x)\n",
    "    \n",
    "    for x_val in x_values:\n",
    "        # Calculate corresponding y value\n",
    "        y_val = L**2 / x_val\n",
    "        # Calculate price ratio\n",
    "        price_ratio = y_val / x_val\n",
    "        \n",
    "        # Calculate valid price range\n",
    "        p_min = price_ratio * (1 - gamma)\n",
    "        p_max = price_ratio / (1 - gamma)\n",
    "        \n",
    "        # Generate evenly spaced prices for each x,y pair\n",
    "        # p_values = np.linspace(p_min, p_max, num_p_per_x)\n",
    "        \n",
    "        # for p_val in p_values:\n",
    "        #     test_states.append([p_val, x_val, y_val])\n",
    "        test_states.append([price_ratio, x_val, y_val])\n",
    "    \n",
    "    return torch.tensor(test_states, dtype=torch.float32)\n",
    "\n",
    "# Generate a comprehensive set of test states\n",
    "# AMM constants\n",
    "L = 10000\n",
    "gamma = 0.003\n",
    "test_states = generate_test_states(L=L, gamma=gamma, num_x=1000, num_p_per_x=100)\n",
    "print(f\"Generated {len(test_states)} test states\")\n",
    "\n",
    "# Evaluate both models on the test states\n",
    "results = []\n",
    "\n",
    "for i, state in enumerate(test_states):\n",
    "    p_val, x_val, y_val = state.tolist()\n",
    "    imm_reward = immediate_reward(state)\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    incoming_value = incoming_model(state.unsqueeze(0)).item() if incoming_model else float('nan')\n",
    "    outgoing_value = outgoing_model(state.unsqueeze(0)).item() if outgoing_model else float('nan')\n",
    "    \n",
    "    # Calculate value difference\n",
    "    value_diff = outgoing_value - incoming_value\n",
    "    \n",
    "    # Calculate normalized position within price bounds\n",
    "    price_ratio = y_val / x_val\n",
    "\n",
    "    \n",
    "    results.append({\n",
    "        'state_idx': i,\n",
    "        'p': p_val,\n",
    "        'x': x_val,\n",
    "        'y': y_val,\n",
    "        'immediate_reward': imm_reward,\n",
    "        'incoming_value': incoming_value,\n",
    "        'outgoing_value': outgoing_value,\n",
    "        'value_diff': value_diff,\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Box plot of value differences across x quantiles\n",
    "x_quantiles = pd.qcut(df['x'], 10, labels=[f'Q{i+1}' for i in range(10)])\n",
    "plt.boxplot([df[x_quantiles == q]['value_diff'] for q in x_quantiles.unique()])\n",
    "plt.xlabel('X Quantiles')\n",
    "plt.ylabel('Value Difference')\n",
    "plt.title('Value Difference Distribution Across X Quantiles')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add quantile range information\n",
    "x_ranges = pd.qcut(df['x'], 10)\n",
    "x_range_labels = [f'{q.left:.1f}-{q.right:.1f}' for q in x_ranges.unique()]\n",
    "plt.xticks(range(1, 11), x_range_labels, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df['x'], df['value_diff'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
