{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing src directory\n",
    "import sys\n",
    "sys.path.append('/Users/andrewcarranti/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src')\n",
    "# experiment imports\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime as dt\n",
    "from scipy.stats import truncnorm\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from scipy.optimize import minimize\n",
    "# project imports\n",
    "from amm.amm import AMM, SimpleFeeAMM\n",
    "from amm.fee import TriangleFee, PercentFee, NoFee\n",
    "# data imports\n",
    "from data.kaiko import fetch_data\n",
    "from api_key.my_api_key import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gbm_assumption_test(log_returns):\n",
    "    adf_result = adfuller(log_returns) # check for stationarity\n",
    "    print(\"ADF Statistic:\", adf_result[0]) # check for stationarity\n",
    "    print(\"P-value:\", adf_result[1])\n",
    "    print(\"Critical Values:\", adf_result[4])\n",
    "    print(\"Stationary:\", adf_result[1] <= 0.05)\n",
    "    # if adf_result[1] > 0.05:  # if not stationary, iteratively difference until achieved\n",
    "    #     for d in range(1, max_lag + 1):\n",
    "    #         diff_data = diff(log_returns, k_diff=d)\n",
    "    #         adf_result = adfuller(diff_data)\n",
    "    #         print(f\"ADF result after differencing level {d}: {adf_result[0]}, p-value: {adf_result[1]}\")\n",
    "    #         if adf_result[1] <= 0.05:\n",
    "    #             print(\"Achieved stationarity with differencing level:\", d)\n",
    "    #             diff_data = diff_data\n",
    "    #             break\n",
    "    shapiro_result = shapiro(log_returns) # check for normality\n",
    "    print(\"Shapiro-Wilk Test Statistic:\", shapiro_result[0])\n",
    "    print(\"p-value:\", shapiro_result[1])\n",
    "    print(\"normal:\", shapiro_result[1] > 0.05)\n",
    "    lb_result = acorr_ljungbox(log_returns, lags=[10], return_df=True) # check for independence (autocorrelation)\n",
    "    print(\"Ljung-Box test:\")\n",
    "    print(lb_result)\n",
    "    print(\"Independent:\", lb_result['lb_pvalue'].iloc[0] > 0.05)\n",
    "    print(\"-\"*50)\n",
    "    # if lb_result['lb_pvalue'].iloc[0] < 0.05: # if autocorrelation detected, adjust\n",
    "    #     print(\"Autocorrelation detected:\") \n",
    "    #     plot_pacf(log_returns, lags=40) # plot partial autocorrelation function\n",
    "    #     plt.title('Partial Autocorrelation Function (PACF)')\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the log-likelihood function\n",
    "def neg_log_likelihood(params, log_returns):\n",
    "    \"\"\"\n",
    "    calculate negative log likelihood of a normal distribution for calibrating GBM\n",
    "    params: tuple, mu and sigma\n",
    "    \"\"\"\n",
    "    mu, sigma = params # define mu and sigma\n",
    "    estimated_mu = np.mean(log_returns) # estimate mu\n",
    "    estimated_var = np.sum((log_returns - estimated_mu)**2) / len(log_returns) # estimate variance\n",
    "    return 0.5 * len(log_returns) * np.log(2 * np.pi * estimated_var) + 0.5 / estimated_var * np.sum((log_returns - mu)**2) # return negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_gbm(asset, data, frequency, T, N, type):\n",
    "    \"\"\"\n",
    "    calibrate geometric brownian motion for next period (t=0 is last observation in data)\n",
    "    \n",
    "    calibrate gbm model by pulling data from kaiko api\n",
    "\n",
    "    asset (str): asset to calibrate\n",
    "    data (pd.DataFrame): price data w/ column 'price'\n",
    "    freq (str): frequency of data (1h, 1d, 1w)\n",
    "    T (float): terminal time\n",
    "    N (int): number of time steps\n",
    "    type (str): type of calibration (reg, mle)\n",
    "    max_lag (int): maximum lag for autocorrelation test (default=10)\n",
    "    alpha (float): significance level for hypothesis tests (default=0.05)\n",
    "\n",
    "    return numpy.ndarray: simulated gbm path\n",
    "    \"\"\"\n",
    "    \n",
    "    if type == \"reg\":\n",
    "        returns = np.log((data / data.shift(1)).dropna()) # get returns\n",
    "        gbm_assumption_test(returns) # test gbm assumptions\n",
    "        mu = returns.mean() * 365.25  # annualized return\n",
    "        sigma = returns.std() * 365.25 ** 0.5 # annualized volatility\n",
    "        print(f'Estimated {asset} {frequency} Mu:', round(mu, 2), 'Estimated Annualized Mu:', round(mu * 365.25,2))\n",
    "        print(f'Estimated {asset} {frequency} Sigma:', round(sigma, 2), 'Estimated Annualized Sigma:', round(sigma * 365.25**0.5, 2))\n",
    "        S0 = data.iloc[-1] # get LAST price in series\n",
    "        dt = T / N # time step size\n",
    "        t = np.linspace(0, T, N)\n",
    "        W = np.random.standard_normal(size=N)\n",
    "        W = np.cumsum(W) * np.sqrt(dt)  # Standard Brownian motion\n",
    "        X = (mu - 0.5 * sigma**2) * t + sigma * W \n",
    "        S = S0 * np.exp(X)  # Geometric Brownian motion    \n",
    "        return S\n",
    "    \n",
    "    elif type == \"mle\":\n",
    "        log_returns = np.log(1 + data.pct_change().dropna()) # calculate log returns\n",
    "        result = minimize(neg_log_likelihood, [0.05, 0.2], args=(log_returns,), bounds=((None, None), (1e-4, None))) # minimize the negative log-likelihood\n",
    "        mu = result.x[0] * 365.25 # annualize mu\n",
    "        sigma = result.x[1] * 365.25**0.5 # annualize sigma\n",
    "        print(f'Estimated {asset} {frequency} Mu:', round(result.x[0],5), 'Estimated Annualized Mu:', round(mu, 5)) # using 365.25 instead of 252 bcs operate 24/7\n",
    "        print(f'Estimated {asset} {frequency} Sigma:', round(result.x[1],5), 'Estimated Annualized Sigma:', round(sigma, 5))\n",
    "        S0 = data.iloc[-1] # get LAST price in series\n",
    "        dt = T / N # time step size\n",
    "        t = np.linspace(0, T, N)\n",
    "        W = np.random.standard_normal(size=N)\n",
    "        W = np.cumsum(W) * np.sqrt(dt)  # standard BM\n",
    "        X = (mu - 0.5 * sigma**2) * t + sigma * W \n",
    "        S = S0 * np.exp(X)  # GBM\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gbm_data(pair, start_date, end_date, freq, api_key):\n",
    "    \"\"\"\n",
    "    get gbm data from kaiko api or local storage\n",
    "\n",
    "    asset (str): asset symbol\n",
    "    start_date (str): start date of data\n",
    "    end_date (str): end date of data\n",
    "    freq (str): frequency of data (1h, 1d, 1w)\n",
    "    api_key (str): kaiko api key\n",
    "\n",
    "    return pd.DataFrame: price data\n",
    "    \"\"\"\n",
    "    # check if data exists, if not fetch data\n",
    "    asset1 = pair.split(\"-\")[0] \n",
    "    asset2 = pair.split(\"-\")[1]\n",
    "\n",
    "    if os.path.exists(f\"/data/crypto_data/{asset1}-usd_{start_date}_{end_date}_{freq}.csv\"):\n",
    "        data1 =  pd.read_csv(f\"/data/crypto_data/{asset1}-usd_{start_date}_{end_date}_{freq}.csv\")[\"price\"]\n",
    "    else: data1 = fetch_data(api_key, asset1+\"-usd\", start_date, end_date, freq)\n",
    "    data1['timestamp'] = pd.to_datetime(data1['timestamp'], unit='ms') # convert timestamp to datetime\n",
    "    data1['price'] = pd.to_numeric(data1['price'])\n",
    "\n",
    "    if os.path.exists(f\"/data/crypto_data/{asset2}-usd_{start_date}_{end_date}_{freq}.csv\"):\n",
    "        data2 =  pd.read_csv(f\"/data/crypto_data/{asset2}-usd_{start_date}_{end_date}_{freq}.csv\")[\"price\"]\n",
    "    else: data2 = fetch_data(api_key, asset2+\"-usd\", start_date, end_date, freq)\n",
    "    data2['timestamp'] = pd.to_datetime(data2['timestamp'], unit='ms') # convert timestamp to datetime\n",
    "    data2['price'] = pd.to_numeric(data2['price'])\n",
    "\n",
    "    return pd.merge(data1, data2, on='timestamp', how='inner', suffixes=(\"_\" + asset1, \"_\" + asset2)) # merge dataframes on timestamp saving price for each asset denominated in USD for storing AMM market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sim1(n, pair, start_dt, end_dt, frequency, spread=0.5):\n",
    "    \"\"\"\n",
    "    simulate AMM market with data calibrated GBM for external oracles and trading agents\n",
    "    n (int): number of simulations\n",
    "    pair (str): asset pair for data (e.g. btc-eth)\n",
    "    asset1_n (int): number of asset1 tokens\n",
    "    asset2_n (int): number of asset2 tokens\n",
    "    start_dt (str): start date for data (YYYY-MM-DD)\n",
    "    end_dt (str): end date for data (YYYY-MM-DD)\n",
    "    frequency (str): frequency of data (1h, 1d, 1w)\n",
    "    spread (float): spread for arbitrage agents (e.g. 0.5%)\n",
    "    return list: list of dataframes for each simulation \n",
    "    \"\"\"\n",
    "\n",
    "    # # SIM STORAGE # #\n",
    "    # create list to store dfs from each simulation of amms\n",
    "    sim_amm_dfs= []\n",
    "    sim_amms = []\n",
    "    # parse asset1 and asset2, create USD denominated pairs\n",
    "    asset1 = pair.split(\"-\")[0] \n",
    "    asset2 = pair.split(\"-\")[1]\n",
    "\n",
    "    # # DATA & GBM CALIBRATION # #\n",
    "    difference = dt.strptime(end_dt, '%Y-%m-%dT%H:%M:%SZ') - dt.strptime(start_dt, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    T_years = difference.days / 365.25  # using 365.25 to account for leap years\n",
    "    marketDF =  get_gbm_data(pair, start_dt, end_dt, frequency, api_key) # get data for assets\n",
    "    n_timesteps = len(marketDF) # number of timesteps in data\n",
    "    # calculate market ratio of asset1/asset2\n",
    "    marketDF[f'mrkt_{asset1}/{asset2}'] = marketDF[f'price_{asset1}'] / marketDF[f'price_{asset2}']\n",
    "    # add columns for trade tracking (amm ratio, inventory, averages)\n",
    "    new_cols = [f'amm_{asset1}/{asset2}', f'{asset1}_inv', f'{asset2}_inv', 'L_inv']\n",
    "    marketDF = marketDF.assign(**{col: None for col in new_cols})\n",
    "    A0 = round(marketDF[f\"price_{asset1}\"][0], 8)*1000000 # initial asset1 inventory based on starting price\n",
    "    B0 = round(marketDF[f\"price_{asset2}\"][0], 8)*1000000\n",
    "    L0 = np.sqrt(A0 * B0)\n",
    "    market_set_portfolio = {\"A\": A0, \"B\": B0, \"L\":L0} # initial portfolio \n",
    "    \n",
    "    gbm_assumption_test(np.log(1 + marketDF[f\"price_{asset1}\"].pct_change().dropna())) # test gbm assumptions\n",
    "    gbm_assumption_test(np.log(1 + marketDF[f\"price_{asset2}\"].pct_change().dropna())) # test gbm assumptions\n",
    "\n",
    "\n",
    "    # # TIME SERIES SIMULATIONS # #\n",
    "    for simulation in range(n): # for each simulation create new set of amms & run new set of trades\n",
    "        market = marketDF.copy() # create new market df for each simulation\n",
    "        nofeeAMM = SimpleFeeAMM(fee_structure = NoFee(), initial_portfolio=market_set_portfolio)\n",
    "        percentAMM = SimpleFeeAMM(fee_structure = PercentFee(0.01), initial_portfolio=market_set_portfolio)\n",
    "        triAMM = SimpleFeeAMM(fee_structure = TriangleFee(0.003, 0.0001, -1), initial_portfolio=market_set_portfolio) \n",
    "        amm_cols = [f'{asset1}_inv', f'{asset2}_inv', 'L_inv', f'{asset1}', f'{asset2}', 'L', f'F{asset1}', f'F{asset2}', 'FL'] # setup new set of dfs to save simulations\n",
    "        percentDF = pd.DataFrame(columns=amm_cols)\n",
    "        nofeeDF = pd.DataFrame(columns=amm_cols)\n",
    "        triDF = pd.DataFrame(columns=amm_cols)\n",
    "        \n",
    "        amms = [(nofeeAMM, nofeeDF), (percentAMM, percentDF), (triAMM, triDF)] # store pairs of amm type & df for updating\n",
    "        marketDF[f'gbm_price_{asset1}'] = calibrate_gbm(asset1, marketDF[f\"price_{asset1}\"], frequency, T_years, n_timesteps, \"mle\") # calibrate gbm for asset1 w/ MLE\n",
    "        marketDF[f'gbm_price_{asset2}'] = calibrate_gbm(asset2, marketDF[f\"price_{asset2}\"], frequency, T_years, n_timesteps, \"mle\") # calibrate gbm for asset2 w/ MLE\n",
    "        marketDF[f'gbm_{asset1}/{asset2}'] = marketDF[f'gbm_price_{asset1}'] / marketDF[f'gbm_price_{asset2}'] # calculate gbm ratio of asset1/asset2\n",
    "        marketDF[f'amm_{asset1}/{asset2}'][0] = A0/B0 # set initial amm ratio\n",
    "\n",
    "        # # SIMULATION # #\n",
    "        for t in range(n_timesteps): # iterate over each timestep in crypto market data\n",
    "            print(marketDF[f'amm_{asset1}/{asset2}'][t])\n",
    "            print((marketDF[f'gbm_{asset1}/{asset2}'][t] * (1+spread/100)))\n",
    "            # # ARBITRAGE AGENT # #\n",
    "            if marketDF[f'amm_{asset1}/{asset2}'][t] > (marketDF[f'gbm_{asset1}/{asset2}'][t] * (1+spread/100)): # rule-based arbitrage agents in the market\n",
    "                asset_out, asset_in, asset_in_n = asset1, asset2, random.choice(list(range(1, 50))) # modeling market efficiency\n",
    "            if (marketDF[f'amm_{asset1}/{asset2}'][t] * 1.005) < marketDF[f'gbm_{asset1}/{asset2}'][t]:\n",
    "                asset_out, asset_in, asset_in_n = asset2, asset1, random.choice(list(range(1, 50)))\n",
    "            else: continue\n",
    "            for amm, df in amms: # update market data with amm data\n",
    "                succ, info = amm.trade_swap(asset_out, asset_in, asset_in_n) # call trade for each AMM\n",
    "                new_row = {f'{asset1}_inv': amm.portfolio[asset1], f'{asset2}_inv': amm.portfolio[asset2], 'LInv': amm.portfolio['L'], # add trade info to df\n",
    "                        asset1: info['asset_delta'][asset1], f'{asset2}': info['asset_delta'][asset2], 'L': info['asset_delta']['L'], \n",
    "                        f'F{asset1}': amm.fees[asset1], f'F{asset2}': amm.fees[asset2], 'FL': amm.fees['L']}\n",
    "                df.loc[t] = new_row # append new row to df\n",
    "        for amm, df in amms:\n",
    "            sim_amm_dfs.append(df)\n",
    "            sim_amms.append(amm)\n",
    "    return sim_amm_dfs, sim_amms # return list of dfs for each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTES FROM LAST MEETING:\n",
    "# FOCUS MORE ON TESTING FEES THROUGH SIM\n",
    "\n",
    "# # EXPERIMENTS TODO: # #\n",
    "# [1] run for large simulations and evaluate over time - explore different time periods to test from (different market conditions and lengths of historical windows) and different frequencies (1h, 1d, 1w)\n",
    "# [2] identify GBM paths that deplete pools (depletion of liquidity) and have both fall in value (impermanent loss) to show how fee accumulation compares ot general trend (law of large #s)\n",
    "        # impermanent loss evaluation could allow for an expected value calculation for LP returns (expected value of fees vs. impermanent loss)\n",
    "# [3] use stock data to see how compares\n",
    "# [4] make sure to highlight how different fee AMMs (basically fees) are affected by different market conditions and therefore how fee accumulation is affected\n",
    "\n",
    "# # UPDATES # #\n",
    "# [1] *importing stock data to use instead of crypto (more in line with goal application and can properly use GBM to simulate)\n",
    "# [2] considering train/test split for calibrating GBM and simulating trades source data (not overly urgent given not forecasting)\n",
    "# [3] maybe also considering changing source data from vwap if stick with crypto data\n",
    "        # multiple price streams for multiple external oracles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -14.089521089313896\n",
      "P-value: 2.737334619240197e-26\n",
      "Critical Values: {'1%': -3.44714244478345, '5%': -2.8689414326247995, '10%': -2.5707127699396084}\n",
      "Stationary: True\n",
      "Shapiro-Wilk Test Statistic: 0.9299114942550659\n",
      "p-value: 1.2842760709064205e-12\n",
      "normal: False\n",
      "Ljung-Box test:\n",
      "      lb_stat     lb_pvalue\n",
      "10  49.980373  2.691357e-07\n",
      "Independent: False\n",
      "--------------------------------------------------\n",
      "ADF Statistic: -13.067648861316895\n",
      "P-value: 1.987006777395487e-24\n",
      "Critical Values: {'1%': -3.4471856790801514, '5%': -2.868960436182993, '10%': -2.5707229006220524}\n",
      "Stationary: True\n",
      "Shapiro-Wilk Test Statistic: 0.9686541557312012\n",
      "p-value: 1.8247985167363368e-07\n",
      "normal: False\n",
      "Ljung-Box test:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.857177   0.000001\n",
      "Independent: False\n",
      "--------------------------------------------------\n",
      "Estimated btc 1d Mu: 0.00251 Estimated Annualized Mu: 0.91566\n",
      "Estimated btc 1d Sigma: 0.2 Estimated Annualized Sigma: 3.8223\n",
      "Estimated eth 1d Mu: 0.00195 Estimated Annualized Mu: 0.71192\n",
      "Estimated eth 1d Sigma: 0.2 Estimated Annualized Sigma: 3.8223\n",
      "14.55242296319956\n",
      "19.9524163589048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/d31q7yf93538r79rbp7dp1b00000gn/T/ipykernel_72788/1089028580.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  marketDF[f'amm_{asset1}/{asset2}'][0] = A0/B0 # set initial amm ratio\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "eth or btc not in portfolio",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[406], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msim1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbtc-eth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-02-01T00:00:00Z\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-03-01T00:00:00Z\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[404], line 70\u001b[0m, in \u001b[0;36msim1\u001b[0;34m(n, pair, start_dt, end_dt, frequency, spread)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m amm, df \u001b[38;5;129;01min\u001b[39;00m amms: \u001b[38;5;66;03m# update market data with amm data\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     succ, info \u001b[38;5;241m=\u001b[39m \u001b[43mamm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrade_swap\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in_n\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# call trade for each AMM\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_inv\u001b[39m\u001b[38;5;124m'\u001b[39m: amm\u001b[38;5;241m.\u001b[39mportfolio[asset1], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_inv\u001b[39m\u001b[38;5;124m'\u001b[39m: amm\u001b[38;5;241m.\u001b[39mportfolio[asset2], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLInv\u001b[39m\u001b[38;5;124m'\u001b[39m: amm\u001b[38;5;241m.\u001b[39mportfolio[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# add trade info to df\u001b[39;00m\n\u001b[1;32m     72\u001b[0m             asset1: info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_delta\u001b[39m\u001b[38;5;124m'\u001b[39m][asset1], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_delta\u001b[39m\u001b[38;5;124m'\u001b[39m][asset2], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m: info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_delta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: amm\u001b[38;5;241m.\u001b[39mfees[asset1], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: amm\u001b[38;5;241m.\u001b[39mfees[asset2], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFL\u001b[39m\u001b[38;5;124m'\u001b[39m: amm\u001b[38;5;241m.\u001b[39mfees[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     74\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[t] \u001b[38;5;241m=\u001b[39m new_row \u001b[38;5;66;03m# append new row to df\u001b[39;00m\n",
      "File \u001b[0;32m~/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src/amm/amm.py:236\u001b[0m, in \u001b[0;36mAMM.trade_swap\u001b[0;34m(self, asset_out, asset_in, asset_in_n)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mThe function should only do swaps.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03masset_out: str - asset to receive\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03masset_in: str - asset to pay\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03masset_in_n: float - amount of asset_in to pay (positive sign for paying fee on input asset, negative sign for paying fee on output asset)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (asset_out, asset_in): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_info\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update liqudity tokens using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrade_swap\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trade\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in_n\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src/amm/amm.py:272\u001b[0m, in \u001b[0;36mSimpleFeeAMM._trade\u001b[0;34m(self, asset_out, asset_in, asset_in_n)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_trade\u001b[39m(\u001b[38;5;28mself\u001b[39m, asset_out: \u001b[38;5;28mstr\u001b[39m, asset_in: \u001b[38;5;28mstr\u001b[39m, asset_in_n: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbool\u001b[39m, Dict]:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# find the amount of asset_out & collect the trade info\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     asset_out_n, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     fees \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# set fees to fee dictionary\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     updates \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_delta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# set updates for call\u001b[39;00m\n",
      "File \u001b[0;32m~/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src/amm/amm.py:223\u001b[0m, in \u001b[0;36mAMM.quote\u001b[0;34m(self, asset_out, asset_in, asset_in_n)\u001b[0m\n\u001b[1;32m    221\u001b[0m is_liquidity_event \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (asset_out, asset_in)) \u001b[38;5;66;03m# check if liquidity event\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_liquidity_event:  \u001b[38;5;66;03m# if not liquidity event\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m asset_in_n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quote_pre_fee\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in_n\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# quote, fee according to sign:\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quote_post_fee(asset_out, asset_in, asset_in_n) \u001b[38;5;66;03m# use + / - symbol to determine pre or post\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quote_no_fee(asset_out, asset_in, asset_in_n)\n",
      "File \u001b[0;32m~/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src/amm/amm.py:194\u001b[0m, in \u001b[0;36mAMM._quote_pre_fee\u001b[0;34m(self, asset_out, asset_in, asset_in_n)\u001b[0m\n\u001b[1;32m    192\u001b[0m fee_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfee_structure\u001b[38;5;241m.\u001b[39mcalculate_fee({asset_out: \u001b[38;5;28;01mNone\u001b[39;00m, asset_in: asset_in_n}, asset_in, portfolio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio, amm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m) \u001b[38;5;66;03m# calc fee \u001b[39;00m\n\u001b[1;32m    193\u001b[0m actual_in_n \u001b[38;5;241m=\u001b[39m asset_in_n \u001b[38;5;241m-\u001b[39m fee_dict[asset_in] \u001b[38;5;66;03m# calc how much goes into public amm inventory pool, less fees\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m asset_out_n, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quote_no_fee\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual_in_n\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# calc how much out w/ fee already deducted\u001b[39;00m\n\u001b[1;32m    195\u001b[0m info\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_delta\u001b[39m\u001b[38;5;124m'\u001b[39m: {asset_out: asset_out_n, asset_in: actual_in_n}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfee\u001b[39m\u001b[38;5;124m'\u001b[39m: fee_dict}) \u001b[38;5;66;03m# add adjusted inventory & fees\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m asset_out_n, info\n",
      "File \u001b[0;32m~/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src/amm/amm.py:208\u001b[0m, in \u001b[0;36mAMM._quote_no_fee\u001b[0;34m(self, asset_out, asset_in, asset_in_n)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quote_no_fee\u001b[39m(\u001b[38;5;28mself\u001b[39m, asset_out: \u001b[38;5;28mstr\u001b[39m, asset_in: \u001b[38;5;28mstr\u001b[39m, asset_in_n: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m, Dict]:\n\u001b[0;32m--> 208\u001b[0m     function_to_solve \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhelper_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_in_n\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# get target function\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     asset_out_n, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver(function_to_solve, left_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio[asset_out] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# solve for asset out amount\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_delta\u001b[39m\u001b[38;5;124m'\u001b[39m: {asset_out: asset_out_n, asset_in: asset_in_n}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfee\u001b[39m\u001b[38;5;124m'\u001b[39m: {}} \u001b[38;5;66;03m# store trade info\u001b[39;00m\n",
      "File \u001b[0;32m~/CODE/SHIFT/2024/py_repo/post_refactor/AMM-Python/src/amm/amm.py:180\u001b[0m, in \u001b[0;36mAMM.helper_gen\u001b[0;34m(self, s1, s2, s2_in)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhelper_gen\u001b[39m(\u001b[38;5;28mself\u001b[39m, s1: \u001b[38;5;28mstr\u001b[39m, s2: \u001b[38;5;28mstr\u001b[39m, s2_in: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[\u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Calculates target value of changed value\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m s1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio \u001b[38;5;129;01mand\u001b[39;00m s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in portfolio\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio[s2] \u001b[38;5;241m+\u001b[39m s2_in \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo enough assets/tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m s1 \u001b[38;5;241m!=\u001b[39m s2, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame s1 and s2 input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: eth or btc not in portfolio"
     ]
    }
   ],
   "source": [
    "\n",
    "sim1(2, \"btc-eth\", '2023-02-01T00:00:00Z', '2024-03-01T00:00:00Z', \"1d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
